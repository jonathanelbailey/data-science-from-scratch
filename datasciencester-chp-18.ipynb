{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An artificial neural network is a predictive model motivated by the way the brain operates.  The brain is a collection of neurons wired together, and each neuron looks at the outputs of the other neurons that feed into it, does a calculation, and then either fires if the calculation exceeds some threshold or doesn't if the condition isn't met.\n",
    "\n",
    "Artificial neural networks consist of artificial neurons, which perform similar calculations over their inputs.  Neural networks can solve a wide variety of problems like handwriting recognition and face detection.  They are used quite heavily in deep learning, which is one of the trendiest fields of data science.  However, most neural networks are \"black boxes\", meaning that inspecting their detail doesn't giove you much understanding of how they are solving a problem.  Large neural networks can be difficult to train, and for most problems, they are probably not the right choice.\n",
    "\n",
    "Pretty much the simplest neural network is the *perceptron*.  Which approximates a single neuron with *n* binary inputs.  It computes a weighted sum of its inputs and \"fires\" if that weighted sum is zero or greater:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from functools import partial\n",
    "from code_python3.linear_algebra import dot\n",
    "import math, random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def step_function(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "def perceptron_output(weights, bias, x):\n",
    "    \"\"\"returns 1 if the perceptron 'fires', 0 if not\"\"\"\n",
    "    return step_function(dot(weights, x) + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron is simply distinguishing between the half spaces separated by the hyperplane of points `x` for which:\n",
    "\n",
    "```python\n",
    "dot(weights,x) + bias = 0\n",
    "```\n",
    "\n",
    "With properly chosen weights, perceptrons can solve a number of simple problems.  For example, we can create an AND gate which returns 1 if both its inputs are 1 but returns 0 if one if its inputs is 0.  It can look like:\n",
    "\n",
    "```python\n",
    "weights = [2,2]\n",
    "bias = -3\n",
    "```\n",
    "\n",
    "If both inputs are 1, the `calculation` equals 2 + 2 - 3 = 1, and the output is 1.  If only one of the inputs are 1, the `calculation` equals 2 + 0 - 3 = -1, and the output is 0.  Similarly, we could build an OR gate with:\n",
    "\n",
    "```python\n",
    "weights = [2.2]\n",
    "bias = -1\n",
    "```\n",
    "\n",
    "and we could build a NOT gate (which has one input and converts 1 to 0 and 0 to 1) with:\n",
    "\n",
    "```python\n",
    "weights = [-2]\n",
    "bias = 1\n",
    "```\n",
    "\n",
    "However, there are some problems that simply can't be solved by a single perceptron.  For example, no matter how hard you try, you cannot use a perceptron to build an XOR gate that outputs 1 if exactly one of its inputs is 1 and 0 otherwise.  This is where we start needing more complicated neural networks.  Of course, you don't need to approximate a neuron in order to build a logic gate:\n",
    "\n",
    "```python\n",
    "and_gate = min\n",
    "or_gate = max\n",
    "xor_gate = lambda x,y: 0 if x == y else 1\n",
    "```\n",
    "\n",
    "Like real neurons, artificial neurons start getting more interesting when you start connecting them together.\n",
    "\n",
    "*Feed forward neural networks* consist of discrete layers of neurons, each connected to the next.  This typically entails an input layer, one or more \"hidden layers\", each of which consists of neurons that take the outputs of the previous layer, performs some calculation, and passes the result to the next layer, and an output layer which produces the final outputs.  Just like the perceptron, each noninput neuron has a weight corresponding to each of its inputs and a bias.  To make our representation simpler, we'll add the bias to the end of our weights vector and give each neuron a bias input that always equals 1.\n",
    "\n",
    "As with the perceptron, for each neuron, we'll sum up the products of its inputs and its weights.  But here, rather than outputing the `step_function` applied to that product, we'll output a smooth approximation of the step function.  In particular, we'll use the `sigmoid` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    return 1 / (1 + math.exp(-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why use `sigmoid` instead of the simpler `step_function`?  In order to train a neural network, we'll need to use calculus, and in order to use calculus, we need smooth functions.  The step function isn't even continuous, and sigmoid is a good smooth approximation of it.  We then calculate the output as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_output(weights, inputs):\n",
    "    return sigmoid(dot(weights, inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this function, we can represent a neuron simply as a list of weights whose length is one more than the number of inputs to that neuron because of the bias weight.  Then we can represent a neural network as a list of noninput *layers*, where each layer is just a list of the neurons in that layer.  That is, we'll represent a neural network as a list (layers) of lists (neurons) of lists (weights).  Given such a representation, using the neural network is quite simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(neural_network, input_vector):\n",
    "    \"\"\"takes in a neural network (represented as a list of lists of lists of weights)\n",
    "    and returns the output from forward-propagating the input\"\"\"\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    for layer in neural_network:\n",
    "\n",
    "        input_with_bias = input_vector + [1]             # add a bias input\n",
    "        output = [neuron_output(neuron, input_with_bias) # compute the output\n",
    "                  for neuron in layer]                   # for this layer\n",
    "        outputs.append(output)                           # and remember it\n",
    "\n",
    "        # the input to the next layer is the output of this one\n",
    "        input_vector = output\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's easy to build the XOR gate that we couldn't build with a single perceptron.  We just need to scale the weights up so that the neuron outputs are either really close to 0 or really close to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 [9.38314668300676e-14]\n",
      "0 1 [0.9999999999999059]\n",
      "1 0 [0.9999999999999059]\n",
      "1 1 [9.383146683006828e-14]\n"
     ]
    }
   ],
   "source": [
    "xor_network = [\n",
    "    [\n",
    "        [20, 20, -30],   # 'and' neuron\n",
    "        [20, 20, -10]    # 'or' neuron\n",
    "    ],\n",
    "    # output layer\n",
    "    [\n",
    "        [-60, 60, -30]\n",
    "    ]\n",
    "]\n",
    "\n",
    "for x in [0,1]:\n",
    "    for y in [0,1]:\n",
    "        # feed forward produces the outputs of every neuron\n",
    "        # feed forward[-1] is the outputs of the output-layer neurons\n",
    "        print(x, y, feed_forward(xor_network, [x, y])[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using a hidden layer, we are able to feed the output of an \"and\" neuron and the output of an \"or\" neuron into a \"second input but not first input\" neuron.  The result is a network that performs \"or, but not and\", which is precisely XOR.\n",
    "\n",
    "Usually we don't build neural networks by hand.  This is in part because we use them to solve much bigger problems.  Instead, we use data to *train* neural networks.  One popular approach is an algorithm called *backpropagation* that has similiaries to the gradient descent algorithm from previous chapters.\n",
    "\n",
    "Imagine we have a training set that consists of input vectors and corresponding target output vectors.  For example, in our previous `xor_network` example, the input vector `[1,0]` corresponded to the target output `[1]`.  And imagine that our network has some set of weights.  We then adjust the weight using the following algorithm:\n",
    "\n",
    "1. Run `feed_forward` on an input vector to produce the output of all the neurons in the network.\n",
    "2. This results in an error for each output neuron -- the difference between ints output and its target.\n",
    "3. Compute the gradient of this error as a function of the neuron's weights, and adjust its weights in the direction that most decreases the error.\n",
    "4. \"Propagate\" these output errors backward to infer errors for the hidden layer.\n",
    "5. Compute the gradients of these errors and adjust the hidden layer's weights in the same manner.\n",
    "\n",
    "Typically we run this algorithm many timesa for our entire training set until the network converges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagate(network, input_vector, target):\n",
    "\n",
    "    hidden_outputs, outputs = feed_forward(network, input_vector)\n",
    "\n",
    "    # the output * (1 - output) is from the derivative of sigmoid\n",
    "    output_deltas = [output * (1 - output) * (output - target[i])\n",
    "                     for i, output in enumerate(outputs)]\n",
    "\n",
    "    # adjust weights for output layer (network[-1])\n",
    "    for i, output_neuron in enumerate(network[-1]):\n",
    "        for j, hidden_output in enumerate(hidden_outputs + [1]):\n",
    "            output_neuron[j] -= output_deltas[i] * hidden_output\n",
    "\n",
    "    # back-propagate errors to hidden layer\n",
    "    hidden_deltas = [hidden_output * (1 - hidden_output) *\n",
    "                      dot(output_deltas, [n[i] for n in network[-1]])\n",
    "                     for i, hidden_output in enumerate(hidden_outputs)]\n",
    "\n",
    "    # adjust weights for hidden layer (network[0])\n",
    "    for i, hidden_neuron in enumerate(network[0]):\n",
    "        for j, input in enumerate(input_vector + [1]):\n",
    "            hidden_neuron[j] -= hidden_deltas[i] * input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty much doing the same thing as if you explicitly wrote the squared error as a function of the weights and used the `minimize_stochastic` function we built previously.\n",
    "\n",
    "Our neural network wants an input to be a vector of numbers.  So we'll transform each image to a vector length 25, whose elements are either 1 or 0.  We'll want our output to indicate which digit the neural network thinks it is, so we'll need 10 outputs.  Then, assuming our inputs are correctly ordered from 0 to 9, our targets will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_digits = [\n",
    "      \"\"\"11111\n",
    "         1...1\n",
    "         1...1\n",
    "         1...1\n",
    "         11111\"\"\",\n",
    "\n",
    "      \"\"\"..1..\n",
    "         ..1..\n",
    "         ..1..\n",
    "         ..1..\n",
    "         ..1..\"\"\",\n",
    "\n",
    "      \"\"\"11111\n",
    "         ....1\n",
    "         11111\n",
    "         1....\n",
    "         11111\"\"\",\n",
    "\n",
    "      \"\"\"11111\n",
    "         ....1\n",
    "         11111\n",
    "         ....1\n",
    "         11111\"\"\",\n",
    "\n",
    "      \"\"\"1...1\n",
    "         1...1\n",
    "         11111\n",
    "         ....1\n",
    "         ....1\"\"\",\n",
    "\n",
    "      \"\"\"11111\n",
    "         1....\n",
    "         11111\n",
    "         ....1\n",
    "         11111\"\"\",\n",
    "\n",
    "      \"\"\"11111\n",
    "         1....\n",
    "         11111\n",
    "         1...1\n",
    "         11111\"\"\",\n",
    "\n",
    "      \"\"\"11111\n",
    "         ....1\n",
    "         ....1\n",
    "         ....1\n",
    "         ....1\"\"\",\n",
    "\n",
    "      \"\"\"11111\n",
    "         1...1\n",
    "         11111\n",
    "         1...1\n",
    "         11111\"\"\",\n",
    "\n",
    "      \"\"\"11111\n",
    "         1...1\n",
    "         11111\n",
    "         ....1\n",
    "         11111\"\"\"]\n",
    "\n",
    "def make_digit(raw_digit):\n",
    "    return [1 if c == '1' else 0\n",
    "            for row in raw_digit.split(\"\\n\")\n",
    "            for c in row.strip()]\n",
    "\n",
    "inputs = list(map(make_digit, raw_digits))\n",
    "\n",
    "targets = [[1 if i == j else 0 for i in range(10)]\n",
    "           for j in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At which point we're ready to build our neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)   # to get repeatable results\n",
    "input_size = 25  # each input is a vector of length 25\n",
    "num_hidden = 5   # we'll have 5 neurons in the hidden layer\n",
    "output_size = 10 # we need 10 outputs for each input\n",
    "\n",
    "# each hidden neuron has one weight per input, plus a bias weight\n",
    "hidden_layer = [[random.random() for __ in range(input_size + 1)]\n",
    "                for __ in range(num_hidden)]\n",
    "\n",
    "# each output neuron has one weight per hidden neuron, plus a bias weight\n",
    "output_layer = [[random.random() for __ in range(num_hidden + 1)]\n",
    "                for __ in range(output_size)]\n",
    "\n",
    "# the network starts out with random weights\n",
    "network = [hidden_layer, output_layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can train it with the backpropagation algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.024382157616321443,\n",
       " 4.684195501636839e-06,\n",
       " 1.6849128340309735e-11,\n",
       " 0.0180391464806713,\n",
       " 0.0007894951820384888,\n",
       " 5.409231346799728e-10,\n",
       " 4.3230780100206996e-08,\n",
       " 0.9698049702048102,\n",
       " 6.704747602428434e-09,\n",
       " 1.3671928428594845e-08]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10,000 iterations seems enough to converge\n",
    "for __ in range(10000):\n",
    "    for input_vector, target_vector in zip(inputs, targets):\n",
    "        backpropagate(network, input_vector, target_vector)\n",
    "        \n",
    "def predict(input):\n",
    "    return feed_forward(network, input)[-1]\n",
    "\n",
    "predict(inputs[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHich indicates that the digit 7 output neuron produces 0.97, while all the other output neurons produce very small numbers.  Although the network's operation is not exactly transparent, we can inspect the weights of the hidden layers to get a sense of what they are recognizing, in particular, we can plot the weights of each neuron as a 5x5 grid corresponding to the 5x5 inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.96, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02, 0.03, 0.0]\n",
      "1 [0.0, 0.96, 0.03, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2 [0.0, 0.02, 0.96, 0.0, 0.0, 0.03, 0.0, 0.0, 0.0, 0.0]\n",
      "3 [0.0, 0.03, 0.0, 0.97, 0.0, 0.0, 0.0, 0.02, 0.0, 0.03]\n",
      "4 [0.0, 0.02, 0.01, 0.0, 0.98, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "5 [0.0, 0.0, 0.02, 0.0, 0.0, 0.96, 0.01, 0.0, 0.02, 0.01]\n",
      "6 [0.0, 0.0, 0.01, 0.0, 0.01, 0.01, 0.99, 0.0, 0.0, 0.0]\n",
      "7 [0.02, 0.0, 0.0, 0.02, 0.0, 0.0, 0.0, 0.97, 0.0, 0.0]\n",
      "8 [0.04, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.0, 0.96, 0.03]\n",
      "9 [0.0, 0.0, 0.0, 0.01, 0.0, 0.02, 0.0, 0.0, 0.03, 0.95]\n",
      ".@@@.\n",
      "...@@\n",
      "..@@.\n",
      "...@@\n",
      ".@@@.\n",
      "[0.0, 0.01, 0.0, 0.97, 0.0, 0.0, 0.0, 0.01, 0.0, 0.1]\n",
      "\n",
      ".@@@.\n",
      "@..@@\n",
      ".@@@.\n",
      "@..@@\n",
      ".@@@.\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.58, 0.0, 0.0, 0.96, 1.0]\n"
     ]
    }
   ],
   "source": [
    "for i, input in enumerate(inputs):\n",
    "    outputs = predict(input)\n",
    "    print(i, [round(p,2) for p in outputs])\n",
    "\n",
    "print(\"\"\".@@@.\n",
    "...@@\n",
    "..@@.\n",
    "...@@\n",
    ".@@@.\"\"\")\n",
    "print([round(x, 2) for x in\n",
    "      predict(  [0,1,1,1,0,    # .@@@.\n",
    "                 0,0,0,1,1,    # ...@@\n",
    "                 0,0,1,1,0,    # ..@@.\n",
    "                 0,0,0,1,1,    # ...@@\n",
    "                 0,1,1,1,0])]) # .@@@.\n",
    "print()\n",
    "\n",
    "print(\"\"\".@@@.\n",
    "@..@@\n",
    ".@@@.\n",
    "@..@@\n",
    ".@@@.\"\"\")\n",
    "print([round(x, 2) for x in\n",
    "      predict(  [0,1,1,1,0,    # .@@@.\n",
    "                 1,0,0,1,1,    # @..@@\n",
    "                 0,1,1,1,0,    # .@@@.\n",
    "                 1,0,0,1,1,    # @..@@\n",
    "                 0,1,1,1,0])]) # .@@@."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFZ9JREFUeJzt3V+IVPf5BvDn1ewm0QiBKCRGXU3JGkUaQ9xEsiCb4IVtQ3tlUEi8EQykXS3olvayhR8E1NK49EZqKUlLy0pzUUKhRKpIpdmuaRN12aghcZPBBk2a0nQ1Xa3v72L3lMlkZ+Z7zvn+PfN8QNA4+54vk32cf4+voqogomqaF/oAROQOA05UYQw4UYUx4EQVxoATVRgDTlRhDDhRhTHgRBXGgBNV2G0uhs6fP19v3brlYrR13d3dWL16dehjGDt//jymp6dDH8NId3c31qxZE/oYxiYmJpK5b++++258+umn0u524qKqKiJ64cKFXF8zOjqKPXv2YGRkBKtXr8b169etnqnZ/N7eXly6dMnqtVxauXIlrl27Btt/gJ48eRI7duzAyMgINm7caGX+XXfdhY8//tjC6fxYvHgxzpw5M+fvjY2NYWhoCCMjI1i1ahWmpqasXjvv/G3btmF8fLxtwKN5ij4wMICRkRE888wzOHHiRHLzfeL941+q359RBPzOO+/Evffei9WrV+Oll17C7t27MTo6msx835577jmcPHnS2rx58+bhjjvuwMaNG/Hyyy9bn5+6hQsXYsWKFVi1ahX279+Pffv2YWxsLIn5wQOehe+jjz7C9evX8fjjj+PQoUPWQuh6fgivvPKKtRBm4f78889x69YtbNq0yer81GXh++CDDzA1NYW+vj4cOHDAWghdzw8a8MbwZWyF0GR+imyFsDHctuenrjF8GVshdD0fCBjwZuHLlA256fxUlQ1hs3DbnJ+yZuHLlA2h6/mZIP8X2oUvUzTkeeanrGgI24Xb1vxUtQtfpmgIXc+v5z3gpuHL5A153vmpyxtC03DbmJ8i0/Bl8obQ9fxGXgNeNHymIe+0cGdMQ5g33L7mxyRP+DKmIcwb7rzz5+It4GXD1y7knRruTLsQlg2f6/mxyBu+TLsQFg236fxmnAW8PoS2wtcs5J0e7kyzENoKn+v5MSjTUGsWwrLhnmu+KWcBz0JoO3yNIWe4v6gxhLbD53p+6hpDbivcjfNNOQv4oUOHsGfPHpw/f956+LKQu5qfuiyEO3bswBtvvGE9fK7npy4L4dDQEN5//31r4a6fb8pZwFPt7lYF7/+wYrl/nAWc3fJwXHfL2V1vzUd33ZSzgLNbHobrbjm766356q6bchbwUN3yTg656255J3TXY+6W1883ZRRwEdkiIudF5F0R+X6Rw/nqlndqyH10y13Oj0Ws3fKi78a3DbiIzAfwUwBfA7AWwHYRWZv7hPDTLe/EkPvqlruaH5MYu+VlPmozeQR/DMC7qvqeqk4D+A2Ab+W6Sh3X3fJOC7nPbnne+SmKrVte9nN0k4DfD+DDul/XZv9bYa675XnmpyzWbnk2P1WxdMttlGRMAj7XYrcvbWoUkV0iclpETptc2HW33HR+qmLvlm/atCn318QkdLfcVgPOJOA1AMvrfr0MwOXGG6nqYVXdoKobTC/uultuMj9F7Jb74bNb7mI+YBbwMQAPisgqEekGsA3A70pdtY7rbnkVu+vslvvjq1vuan7bgKvqTQDfAfAHABMARlR1vPSV67julletu85uuV8+uuWu5ht9Dq6qv1fVXlX9iqr+n5UrN2B32hzvH/9S/f6MYjMe96Lnw265X9yLXgL3oufHbrk/3IteAveiF8NuuR/ci14C96KXE3u3nHvRw87PcC96wmLtlnMvetj59bgXPXHci25XbN1y7kW3MD913ItuT4zdcu5FtzA/ddyLbkes3XLuRe/gcGe4F728mLvl3IveweHOcC96WNyLbkHVuuW2cS96WNyLnsD81PH+DyuW+4d70SuIe9HD4l70EqrYLbeJe9HD4l507kV3hnvRy4u5W+5sL7oN3IvuFvei2xFrt9zZXnSbuBfdDe5FtyfGbnmZj9pE9UsLUkvr7u7WGzduWJ/rQk9PDyYmJkIfw1hvby9qtVroYxhZunRpMmcFZmqqqZx38eLFuHr16lwbj7/AScBFxP5QR65duxb6CLksWLAAFy9eBFCuwTc6OorBwUEMDw83/Vt1Zec/++yzSX0+Pm/ePOzatQsAcPnyZRw7dgybN2/G0qVL57x9b28vdu3ahcOHD+PChQu5rlV2/quvvmoU8LT/0m4Hs9HtHx4exuDgoLO99ClbunQpNm/ejGPHjuHy5S9tCS8Vbh/zMwx4gmx2++cKOeu/M5qF0Fb4XM8HGPAk2e7214ec4f6ixhDaDJ+P+Qx4glx0+4eHh7F792688847DHeDLITHjx/HmjVrrIXPx3wGPEHslvuXarefAU9QszfGisqelj/00EM4dOiQ9fmpy542T0xM4Mknn2z6xliM8xnwBLV69zuvubr9NuenrvE1cbt3v2Obz4AnyFYIW3X7GfLm72bbCqHr+QADnqyyITTp9pedn7J272aXDaHr+RkGPGFFQ5in219mfqpMP6oqGkLX8+sx4InLG8Iie+mLzk9R3s+h84bQ9fxGDHgFmIawzF56l/NjUqRkYhrCoiWWMiFnwCvCR7fc5fxYxNotLxpyBrxCXHfLO6G7HnO3vH6+KQa8Ylx3y9ldb81Xd90UA15Brrvl7K635qO7bqptwEXk5yJyRUTOlToVeZVqd7oqYrl/TB7BfwFgi+NzkEWuu+Xsrrfmo7tuqm3AVfUkgH+UORD547pbzu56a76666b4GrxCXHfLO6G7HnO3vH6+KWsBF5FdInJaRE7bmknmfHTLXc6PRazd8qLvxlsLuKoeVtUNqrrB1kwy46tb7mp+TGLslpf5qI1P0RPns1ued36KYuuWl/0c3eRjsl8D+DOA1SJSE5Gdua9CTsTaLc/mpyqWbrmNkozJu+jbVfU+Ve1S1WWqeqTQlciq2Lvl3Isedn6GT9ETxG65H9yLTkGwW+4P96KTd+yW+8W96OQVu+X+pdrtZ8ATxG65X9yLTl6xW+4P96KTd+yW+8G96BRM7N1y7kUPOz/DgCcs1m4596KHnV+PAU8c96LbFVu3nHvRiXvRLYqxW8696MS96JbE2i3nXnTiXnQLYu6Wcy86cS96YNyLTs5xL3pYSe1FpzSl2p2uiljuH1FV60Nvv/12nZ6etj7XhRUrVuTaUhna888/j8nJydDHMNLT05PUZpcXXngBtVot9DGMrF27FuPj49Ludre5uPj09DRqtdr/nraNjo5icHAQw8PDpTd9zPWar8z8Bx98sNR5fDt3Lq1/YOb48eOhj2CsVqvh7NmzpWYsXLgQy5cvx4cffoipqSkAwNjYGPbu3YuDBw+ir6/PyvyHH37Y6PbOnqJzLzelaGxsrPDXzhVuAOjr68PBgwexd+9ea/NNeXsNHnt3mghA4RA2C3embMjbzW/G65tssXaniTJFQmgavqIhLxpuIMC76LF1p4nq5Q1h3vC5nt8oyMdkMXWniRqZhrBo+FzPrxfsc/BYutNEc2kXwrLhcz0/E7ToEkN3mqiZZiG0FT7X84EImmzsTlPMGkNoM3w+5gcPOMDuNMUtC+G+ffvw3nvvWQufj/lRBBxgd5rilur3ZxQBd72Xm3u/qYzsafMDDzyAAwcOlG6k+ZwfPOCu93Jz7zeV0fia2Fbt1Nf8oAF33S03mU/UjM9uuYv5QMCA+9jLbTKfaC6hu+W2Qh4k4L72cpvMJ2oUS7fcRsi9B9znXm5+FEZ5xdYtLxvytgEXkeUiclxEJkRkXET25L7KLO7lptjF2C0vE3KTR/CbAPaq6hoAGwF8W0TW5roKuJeb0hBrt7xoyNsGXFX/rqp/nf35ZwAmANzf7uu4l5tSFHO3vH6+qVyvwUVkJYBHALR9McxuOXUiX911U8YBF5G7APwWwHdV9V9z/P4uETktIqcBsFtOHctHd92UUcBFpAsz4f6Vqr46121U9bCqblDVDUC63V0iG2L5/jR5F10AHAEwoao/Nh3Mbjl1Kh/ddVMmj+D9AJ4D8JSIvDX74+vtvojdcupEvrrrpkzeRf+TqoqqflVV18/++H27r+NedEpRzN1y7kVnyKmkWLvl3IteYj5RJsZuOfeil5hPVC+2bjn3opecT9Qolm4596JbmE80l9Ddcu5FtzSfqBnuRbeAe9EpZtyLbgH3olPMuBfdAnbXKWapfn9GEXDuRaeYcS96CdyLTjHjXvQSuBedYsa96CVwLzrFLHS3nHvRLc0nahRLt5x70S3MJ6oXW7fc+V50m7gXnWIXY7fc9V50K7gXnVIQa7e8aMhFVXNfrJ2uri69efOm9bku9PT04Ny5c6GPYWzdunWYnJwMfQwjPT09mJiYCH0MY729vajVaqGPYWTdunU4e/astLvdbS4uvmDBAvT397sYbd3IyEjoI+QyOTmJq1evtrzNqVOnsHPnThw5cgQDAwNYtGgRPvvsM9y4ccPKGUznL1myxMr1fKnVarh48WLpOaOjoxgcHMTw8DAGBgasP7McHR3Fiy++aHTb4EUXsq+/vx9HjhzBzp078eabb1oNt4/5qfPxdytMMeAVlWp3uipiuX8Y8Arq6urCokWL8Oijj/7vkfbUqVPJzE+dj79bYYoBr5gsfNnT5vqn0zZC6Hp+6nz93QpTDHiFNIYvYyuErufHIOa9/UU2ETHgFdEsfJmyIXQ9Pxax7u0v2vNgwCugXfgyRUPoen5MYtzbX6bExYAnzjR8mbwhLDM/RbHt7S/b0GTAE5Y3fBnTkJedn6qY9vaXLckw4IkqGr5Mu5DbmJ+yWPb2ly3JMOAJKhu+TLOQ25qfuhj29pdtwDHgCbIZvsaQM9xflPrefgY8QeyW+5Xy3n4GPEHslvuXarefAU8Qu+V+pby3nwFPELvl/qS+t79twEXkDhH5i4i8LSLjIvLD0lelUtgt9yOGvf1lQ27yCP4fAE+p6sMA1gPYIiIbS12VSou9W97V1ZX7a2ISultuK+RtA64z/j37y67ZH/YXuVFusXbLs/mpiqVbbiPkRq/BRWS+iLwF4AqA11WV/6hXJHx2y/POT1Fs3fKyITcKuKr+V1XXA1gG4DERWdd4GxHZJSKnReT09PR07oNQcb665a7mxyTGbnmZkOd6F11V/wngBIAtc/zeYVXdoKoburu7cx2CyvPRLXc5PxaxdsuLhtzkXfQlInL37M/vBLAZwDu5T0jOue6Wd0J3PeZueZF/FdfkEfw+AMdF5AyAMcy8Bn+t4BnJMdfdcnbXW/PVXTdl8i76GVV9RFW/qqrrVPVHpU5IznEveljci07OpdqdropY7h8GvIK4Fz0s7kUnZ7gXPSzuRSdnuBe9vJi75dyL3sG4F92OWLvl3IvewbgX3Z4Yu+Xci97BuBfdrti65dyL3sFi7ZZzL3rY+fUY8ETF3i3nXvSw8zMMeILYLfeDe9EpCHbL/eFedPKO3XK/uBedvGK33L9Uu/0MeILYLfeLe9HJK3bL/an8XnSKD7vlflRhL7qo2t+AvH79ej127Jj1uS5cu3Yt9BFy6e/vR61WC30MI8uXL0/qD4gnnngimft27dq1GB8fl3a3u83HYcieWq2G+j+UT5w4ga1bt+Lo0aMYGBiwfr0y80Xafv9FpVar4e2338bChQvR09ODyclJTE1NtfyasbExDA0NYf/+/ejr6zO6jo3527dvN7oWn6InbmBgAEePHsXWrVudvbvrcn5s8oQPAPr6+rB//34MDQ1hbGws+PxGDHgFMOT25AlfxjSEecOdd/5cGPCKYMjtyBu+TLsQFg236fxmGPAKYcjLKxK+TLMQlg33XPNNMeAVw5CH1RhyW+FunG+KAa8ghjys+pBfunTJWrjr55tiwCuKIQ8rlvuHAa8whjyM7Gn5ypUrS33E1Wq+KQa84hhyvxpfc5f9HLvZfFMMeAdgyM2VCWGzN9Rshbx+vikGvEMw5GaKhrDdu+VlQ1703XgGvIMw5O0VCaFp+IqGvMxHbQx4h/EZ8hTF1i0v+zk6A96BfIU8VbF0y22UZBjwDuUj5CkL3S231YBjwDtYFV4zu+SzW+5iPpAj4CIyX0T+JiKvlboiRYUhb81Xt9zV/DyP4HsATJS+IkWHIW/NR7fc1XyjgIvIMgDfAPAzK1elUvgRl3+pfsRo+gj+EwDfA3DL2pWpsNS+yVLno1vuan7bgIvI0wCuqOqbbW63S0ROi8jpTz75xMrhaG4pPpKkyle33NV8k0fwfgDfFJFLAH4D4CkR+WXjjVT1sKpuUNUN99xzT+mDUXOpPl1Mjc9uuYv5gEHAVfUHqrpMVVcC2Abgj6r6bKmrUmkMuVuhu+W2Qs7PwRPGkLsRS7fcRshzBVxVT6jq04WuRE4w5HbF1i3nXnRiyC2KsVvOvejEkFsSa7ece9GJIbcg5m4596ITQx4Y96KTcwx5WNyLTs4x5GHFcv8w4BXGkIfBvejkDUPuF/eik3cMubmYu+Xci05NMeRmYu2Wcy86tcWQtxdjt5x70ckY96K3Flu3nHvRKTfuRW8tlm4596JTYdyL3lrobjn3olNpVXjN7FJH7UWnamLIW+ukvehUUQx5aynvRRdVtTLoC0NFrgIw/zTezGIAH1ue6VJK503prEBa53V11h5VXdLuRk4C7oKInFbVDaHPYSql86Z0ViCt84Y+K5+iE1UYA05UYSkF/HDoA+SU0nlTOiuQ1nmDnjWZ1+BElF9Kj+BElFMSAReRLSJyXkTeFZHvhz5PKyLycxG5IiLnQp+lHRFZLiLHRWRCRMZFZE/oMzUjIneIyF9E5O3Zs/4w9JlMiMh8EfmbiLwW4vrRB1xE5gP4KYCvAVgLYLuIrA17qpZ+AWBL6EMYuglgr6quAbARwLcjvm//A+ApVX0YwHoAW0RkY+AzmdgDYCLUxaMPOIDHALyrqu+p6jRm/oXTbwU+U1OqehLAP0Kfw4Sq/l1V/zr7888w8414f9hTzU1n/Hv2l12zP6J+A0lElgH4BoCfhTpDCgG/H8CHdb+uIdJvwpSJyEoAjwAYDXuS5maf7r4F4AqA11U12rPO+gmA7wG4FeoAKQRc5vhvUf/JnRoRuQvAbwF8V1X/Ffo8zajqf1V1PYBlAB4TkXWhz9SMiDwN4IqqvhnyHCkEvAZged2vlwG4HOgslSMiXZgJ969U9dXQ5zGhqv8EcAJxv9fRD+CbInIJMy8rnxKRX/o+RAoBHwPwoIisEpFuANsA/C7wmSpBRATAEQATqvrj0OdpRUSWiMjdsz+/E8BmAO+EPVVzqvoDVV2mqisx8z37R1V91vc5og+4qt4E8B0Af8DMm0Ajqjoe9lTNicivAfwZwGoRqYnIztBnaqEfwHOYeXR5a/bH10Mfqon7ABwXkTOY+UP/dVUN8tFTSthkI6qw6B/Biag4BpyowhhwogpjwIkqjAEnqjAGnKjCGHCiCmPAiSrs/wF664RLBVTIBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAACb5JREFUeJzt3d+LlQUex/HPRxtrMithC0Jl7SJiLdiKwQJvyrqwjLotqqvAizYwCKKgG/+B6KYu7ActFFZQQVRLCBUVtdVUFrnTglhLUqRDhSOFYn32YuYiyvE8x3meeeZ8eb9gYI4+PH6Qec9zzpnhHCcRgJqW9T0AQHcIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCTuvipKeffnrGx8e7OHXrxsbG+p4wlOnp6b4nDGX16tV9T2jsnHPO6XtCY9PT05qZmfGg4zoJfHx8XFdffXUXp27d+eef3/eEoTz22GN9TxjKtdde2/eExrZu3dr3hMZ27NjR6DjuogOFEThQGIEDhRE4UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4UROFAYgQOFEThQGIEDhRE4UFijwG1vsf1f2/ts39/1KADtGBi47eWSHpF0vaQNkm61vaHrYQAWrskVfKOkfUn2Jzkm6VlJN3c7C0AbmgS+RtI3v7t9YO7PACxxTQI/0Ss3/ulNxW1vsz1pe/LYsWMLXwZgwZoEfkDSut/dXivp2z8elGRnkokkEytWrGhrH4AFaBL4R5Iusn2h7RWSbpH0crezALRh4OuiJzlu+25Jr0taLunJJHs7XwZgwRq98UGS1yS91vEWAC3jN9mAwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCnPzpBVIX7JJLLslzzz3X+nm78M477/Q9YSj2iV7kdun6/vvv+57Q2P79+/ue0Nirr76q6enpgV8MXMGBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCBgZu+0nbB21/sRiDALSnyRX8KUlbOt4BoAMDA0/ytqQfFmELgJbxGBworLXAbW+zPWl78scff2zrtAAWoLXAk+xMMpFkYvXq1W2dFsACcBcdKKzJj8l2SXpf0sW2D9i+s/tZANpw2qADkty6GEMAtI+76EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFDbwBR9OxaFDh/Too492cerWXXPNNX1PGMptt93W94Sh7Nq1q+8JjV1xxRV9T2jsvffea3QcV3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKCwgYHbXmf7TdtTtvfa3r4YwwAsXJOXbDou6d4kn9heJelj27uT/KfjbQAWaOAVPMl3ST6Z+3xG0pSkNV0PA7BwQz0Gt71e0uWSPuhiDIB2NQ7c9lmSXpB0T5LDJ/j7bbYnbU/+8ssvbW4EcIoaBW57TLNxP5PkxRMdk2RnkokkE+Pj421uBHCKmjyLbklPSJpK8lD3kwC0pckVfJOkOyRttr1n7uOGjncBaMHAH5MleVeSF2ELgJbxm2xAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhTd74YGgrV67UlVde2cWpW/fSSy/1PWEoK1eu7HvCUKampvqe0NiDDz7Y94TGduzY0eg4ruBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhAwO3fYbtD21/Znuv7WYvJQGgd01esumopM1Jjtgek/Su7X8l+XfH2wAs0MDAk0TSkbmbY3Mf6XIUgHY0egxue7ntPZIOStqd5INuZwFoQ6PAk/ya5DJJayVttH3pH4+xvc32pO3JmZmZtncCOAVDPYue5CdJb0nacoK/25lkIsnEqlWrWpoHYCGaPIt+nu1z5z4fl3SdpC+7HgZg4Zo8i36BpH/aXq7ZbwjPJ3ml21kA2tDkWfTPJV2+CFsAtIzfZAMKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoLAmr+gytGXLlunMM8/s4tStu+uuu/qeMJQjR44MPmgJ+fnnn/ue0NhXX33V94TGjh492ug4ruBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhjQO3vdz2p7Zf6XIQgPYMcwXfLmmqqyEA2tcocNtrJW2V9Hi3cwC0qekV/GFJ90n6rcMtAFo2MHDbN0o6mOTjAcdtsz1pe/Lw4cOtDQRw6ppcwTdJusn215KelbTZ9tN/PCjJziQTSSbOPvvslmcCOBUDA0/yQJK1SdZLukXSG0lu73wZgAXj5+BAYUO9s0mStyS91ckSAK3jCg4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhTmJO2f1D4k6X8tn/YvkqZbPmeXRmnvKG2VRmtvV1v/muS8QQd1EngXbE8mmeh7R1OjtHeUtkqjtbfvrdxFBwojcKCwUQp8Z98DhjRKe0dpqzRae3vdOjKPwQEMb5Su4ACGNBKB295i+7+299m+v+89J2P7SdsHbX/R95ZBbK+z/abtKdt7bW/ve9N8bJ9h+0Pbn81t3dH3piZsL7f9qe1X+vj3l3zgtpdLekTS9ZI2SLrV9oZ+V53UU5K29D2ioeOS7k3yN0lXSfrHEv6/PSppc5K/S7pM0hbbV/W8qYntkqb6+seXfOCSNkral2R/kmOafYfTm3veNK8kb0v6oe8dTST5Lsknc5/PaPYLcU2/q04ss47M3Ryb+1jSTyDZXitpq6TH+9owCoGvkfTN724f0BL9IhxlttdLulzSB/0umd/c3d09kg5K2p1kyW6d87Ck+yT91teAUQjcJ/izJf2de9TYPkvSC5LuSXK47z3zSfJrksskrZW00falfW+aj+0bJR1M8nGfO0Yh8AOS1v3u9lpJ3/a0pRzbY5qN+5kkL/a9p4kkP2n2XW6X8nMdmyTdZPtrzT6s3Gz76cUeMQqBfyTpItsX2l4h6RZJL/e8qQTblvSEpKkkD/W952Rsn2f73LnPxyVdJ+nLflfNL8kDSdYmWa/Zr9k3kty+2DuWfOBJjku6W9Lrmn0S6Pkke/tdNT/buyS9L+li2wds39n3ppPYJOkOzV5d9sx93ND3qHlcIOlN259r9pv+7iS9/OhplPCbbEBhS/4KDuDUEThQGIEDhRE4UBiBA4UROFAYgQOFEThQ2P8BrrsOt6Q6ePwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def patch(x, y, hatch, color):\n",
    "    \"\"\"return a matplotlib 'patch' object with the specified\n",
    "    location, crosshatch pattern, and color\"\"\"\n",
    "    return matplotlib.patches.Rectangle((x - 0.5, y - 0.5), 1, 1,\n",
    "                                        hatch=hatch, fill=False, color=color)\n",
    "\n",
    "def show_weights(neuron_idx):\n",
    "    weights = network[0][neuron_idx]\n",
    "    abs_weights = [abs(weight) for weight in weights]\n",
    "\n",
    "    grid = [abs_weights[row:(row+5)] # turn the weights into a 5x5 grid\n",
    "            for row in range(0,25,5)] # [weights[0:5], ..., weights[20:25]]\n",
    "\n",
    "    ax = plt.gca() # to use hatching, we'll need the axis\n",
    "\n",
    "    ax.imshow(grid, # here same as plt.imshow\n",
    "              cmap=matplotlib.cm.binary, # use white-black color scale\n",
    "              interpolation='none') # plot blocks as blocks\n",
    "\n",
    "    # cross-hatch the negative weights\n",
    "    for i in range(5): # row\n",
    "        for j in range(5): # column\n",
    "            if weights[5*i + j] < 0: # row i, column j = weights[5*i + j]\n",
    "                # add black and white hatches, so visible whether dark or light\n",
    "                ax.add_patch(patch(j, i, '/', \"white\"))\n",
    "                ax.add_patch(patch(j, i, '\\\\', \"black\"))\n",
    "    plt.show()\n",
    "    \n",
    "show_weights(0)\n",
    "show_weights(1)\n",
    "show_weights(2)\n",
    "show_weights(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the first hidden neuron has large positive weights in the left column and in the center of the middle row, while it has large negative weights in the right column.  On those inputs, it does what you'd expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999891931095952\n",
      "0.007128731038157492\n",
      "[[1.2885453726823725e-09, 0.9689434353613953, 0.0014204929460003945, 0.9831123286718932, 3.694766808960256e-05], [0.15184726081855648, 1.977719860654913e-06, 1.1719495168352514e-11, 0.007084473598436873, 0.002042164504235355, 2.8408705017464553e-10, 1.3086865586678795e-07, 0.9866434205668683, 8.815605117295454e-09, 2.5873730366856654e-09]]\n"
     ]
    }
   ],
   "source": [
    "left_column_only = [1, 0, 0, 0, 0] * 5\n",
    "print(feed_forward(network, left_column_only)[0][0])\n",
    "\n",
    "center_middle_row = [0, 0, 0, 0, 0] * 5\n",
    "print(feed_forward(network, center_middle_row)[0][0])\n",
    "\n",
    "right_column_only = [0, 0, 0, 0, 1] * 5\n",
    "print(feed_forward(network, right_column_only))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
